## 2021년 1월 7일

윤준우
- 데이터 preprocessing
- 데이터 EDA 
이경수
train quality feature selection
- train_err 변수 상관관계 (변수형이기 때문)
- model - error type 43%
- fever - error type 20%
- error type - err code 50%

이지수
- 베이스라인만 실행해봄

정지영
- error code 군집화로 트레인 돌리기
- pca=3 으로 0.05정도 상승

양희정
- 베이스라인 실행해봄
- 일별 합산 데이터 추가 해서 돌려봄
- 일별로 errtype 추가 중  

Todo
- 데이터, 빙향성 살펴보기
- 주말에 각자 역할정하기 (Preprocessing, EDA, Modeling, Fine-tuning&Ensemble)


## 2021년 1월 8일

이경수
- 차원축소는 별로 효과가 없다
- 모델이랑 펌웨어랑은 상관관계 거의 1
- errtype고려하면 그저 그럼
- 

정지영
- 코랩 쉐어 파일
- pca로 군집화 하여 실행시켜봄

윤준우
- 코랩 쉐어 eda 
- train_prob살펴봄
- days를 넣으면 auc 0.15오름 

이지수 
- 모델 스태킹해봄

단체토론
- 퀄리티 데이터란 무엇인가…?
-      시스템 퀄리티 로그
-      NaN value가 많은 퀄리티도 있음
-      퀄리티 3,4 는 아예 전부 0임
-      원론적으로 퀄리티 로그가 무엇을 뜻하는  지 예측해봐야 문제를 풀 수 있지 않을까
- 단순하게 모델링에 집중하면 당장은 점수를 올릴 수 있지만 인사이트가 필요함

TODO
- 각자 코드 완성해서 올려놓기
- 인사이트 도출해보기
- 데이터 살펴보기

## 2021년 1월 9일

양희정
- time, user 아이디빼고 펌웨어,모델 살펴봄
- 같은 유저아이디 기준 펌웨어, 모델은 같다
- errtype 원핫인코딩 예정
윤준우
- Feature importance 로 중요하고 크리티컬한 feature을 추려봄
-    모델 2,3번 / errorcode 0, 2, 3 terminate by peer user 그리고 많은 errtype과 days가 중요했음
- errcode는 크게 모델 성능을 높이진 못했음 
- days는 모델 성능을 높여줌 -> 로그기록이 많을수록 문제제기 확률이 높다?
이경수
- 펌웨어, 모델 중 하나는 없에야할 듯
- day도 제외해봄 크게 상관없는 것 같음
- 퀄리티 데이터도 중요하고 연관성을 찾아야해서 중점적으로 살펴봄
- NaN이 많은 데이터가 있어 어떤 커ㅜㄹ리티는 제외해봐야할듯
- 아이디만 다르고 날짜,시간,펌웨어 같을 때 보니까 특정 부분만 숫자가 다름
-        시간이 다르면 특정 퀄리티가 올라가는 양상이 있나?
- 펌웨어를 바꿔봤는데 특정하지 못함
- 유저아이디 다르고 분단위로 봤을 때 비슷한 양상을 보였지만 확실하지 않음
- 확실한 거: 날짜가 달라지면 양상이 틀려짐
- 모든조건이 같아도 아이디에 따라 퀄리티가 다르다
정지영
- 군집화 해봄 - 유니크한 건 0번군집에 들어가기에 그대로 PCA함
- 11월 넘어가는 건 한 곳에 넣음
- 펌웨어 메이저 버전으로 바꾼뒤에 모델 숫자를 뒤어 붙여서 만듬
- 유저아이디마다 데이터 수가 적고 그런 사람도 고장이 많음
- 에러타입 발생할 확률 따로 만들어봄


**토론
거의다 모델이 같지만 모델이 다른 경우는 문제가 있어서가 아닌가 살펴봐야하지 않을까
problem은 사용자 불만 및 불만이 접수된 시간임으로 그전에 문제가 발생한거임
크리티컬 안했으면 접수를 안했다


정지영 - 에러타입 군집화, 에러코드 확률 
이경수 - 퀄리티 데이터 에러타입 관계 찾고, 머지해서 모델링 / 크리티컬한 문제가 있는지
양희정 - 크리티컬한 에러코드, 타입을 찾아보고 
윤준우 - 문제 제기한 시간을 어떻게 이용할지, 이를 이용해서 에러코드, 타입 narrow화




역할
데이터 전처리 1
EDA 1
피쳐 엔지니어링 2
모델링 (Tree-model, shap, bourta 등으로 feature selection 포함)

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
이때까지 한 것 

데이터 전처리
 - data type 변환
 - null 전처리

피처 preprocessing&generation
 - days feature 만들기
 - errorcode Label encoding
 - quality PCA using K-Means

모델링&스태킹
 - pycaret으로 자동 ensemble
ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ

진행 시 참고할만한 사항
Numeric Data - treebased model일때 feature scaling(minimax, std)에 영향을 받지 않음
Frequence Encoding - 지금처럼 user id fréquence encoding으로 진행시 최대 aux 0.85~6나올듯  - 뭔가 신선한 인사이트가 필요
quality 중 Null value가 많은 건 어떻게 다뤄야할지
quality 사용시 pca로 핸들링 했을 때 크게 작용하지 않음
특정 days와 errcode, errtype이 크게 작용함
——————————————-
데이터 고찰
- 오류는 분명 특이시점에 발생했는데 이를 무시하고 유저에게 오류가 발생했으면 전부 오류를 1로 치환한다? 그것은 조금 말이 안됌
- 사계열 데이터처럼 시간별 로그 기록이기 때문에 오류가 발생하기 이전에는 정상이였을 가능성이 있음
- 즉 오류가 발생한 시점 시간대만 1로 치환해보면 어떨까
———————————————
