# LG 대회를 진행하며 기록한 회의록
-- 윤준우 작성 
## 2021년 1월 7일

윤준우
- 데이터 preprocessing
- 데이터 EDA 
이경수
train quality feature selection
- train_err 변수 상관관계 (변수형이기 때문)
- model - error type 43%
- fever - error type 20%
- error type - err code 50%

이지수
- 베이스라인만 실행해봄

정지영
- error code 군집화로 트레인 돌리기
- pca=3 으로 0.05정도 상승

양희정
- 베이스라인 실행해봄
- 일별 합산 데이터 추가 해서 돌려봄
- 일별로 errtype 추가 중  

Todo
- 데이터, 빙향성 살펴보기
- 주말에 각자 역할정하기 (Preprocessing, EDA, Modeling, Fine-tuning&Ensemble)


## 2021년 1월 8일

이경수
- 차원축소는 별로 효과가 없다
- 모델이랑 펌웨어랑은 상관관계 거의 1
- errtype고려하면 그저 그럼
- 

정지영
- 코랩 쉐어 파일
- pca로 군집화 하여 실행시켜봄

윤준우
- 코랩 쉐어 eda 
- train_prob살펴봄
- days를 넣으면 auc 0.15오름 

이지수 
- 모델 스태킹해봄

단체토론
- 퀄리티 데이터란 무엇인가…?
-      시스템 퀄리티 로그
-      NaN value가 많은 퀄리티도 있음
-      퀄리티 3,4 는 아예 전부 0임
-      원론적으로 퀄리티 로그가 무엇을 뜻하는  지 예측해봐야 문제를 풀 수 있지 않을까
- 단순하게 모델링에 집중하면 당장은 점수를 올릴 수 있지만 인사이트가 필요함

TODO
- 각자 코드 완성해서 올려놓기
- 인사이트 도출해보기
- 데이터 살펴보기

## 2021년 1월 9일

양희정
- time, user 아이디빼고 펌웨어,모델 살펴봄
- 같은 유저아이디 기준 펌웨어, 모델은 같다
- errtype 원핫인코딩 예정
윤준우
- Feature importance 로 중요하고 크리티컬한 feature을 추려봄
	- 모델 2,3번 / errorcode 0, 2, 3 terminate by peer user 그리고 많은 errtype과 days가 중요했음
- errcode는 크게 모델 성능을 높이진 못했음 
- days는 모델 성능을 높여줌 -> 로그기록이 많을수록 문제제기 확률이 높다?
이경수
- 펌웨어, 모델 중 하나는 없에야할 듯
- day도 제외해봄 크게 상관없는 것 같음
- 퀄리티 데이터도 중요하고 연관성을 찾아야해서 중점적으로 살펴봄
- NaN이 많은 데이터가 있어 어떤 커ㅜㄹ리티는 제외해봐야할듯
- 아이디만 다르고 날짜,시간,펌웨어 같을 때 보니까 특정 부분만 숫자가 다름
	- 시간이 다르면 특정 퀄리티가 올라가는 양상이 있나?
- 펌웨어를 바꿔봤는데 특정하지 못함
- 유저아이디 다르고 분단위로 봤을 때 비슷한 양상을 보였지만 확실하지 않음
- 확실한 거: 날짜가 달라지면 양상이 틀려짐
- 모든조건이 같아도 아이디에 따라 퀄리티가 다르다
정지영
- 군집화 해봄 - 유니크한 건 0번군집에 들어가기에 그대로 PCA함
- 11월 넘어가는 건 한 곳에 넣음
- 펌웨어 메이저 버전으로 바꾼뒤에 모델 숫자를 뒤어 붙여서 만듬
- 유저아이디마다 데이터 수가 적고 그런 사람도 고장이 많음
- 에러타입 발생할 확률 따로 만들어봄


**토론
거의다 모델이 같지만 모델이 다른 경우는 문제가 있어서가 아닌가 살펴봐야하지 않을까
problem은 사용자 불만 및 불만이 접수된 시간임으로 그전에 문제가 발생한거임
크리티컬 안했으면 접수를 안했다


정지영 - 에러타입 군집화, 에러코드 확률 
이경수 - 퀄리티 데이터 에러타입 관계 찾고, 머지해서 모델링 / 크리티컬한 문제가 있는지
양희정 - 크리티컬한 에러코드, 타입을 찾아보고 
윤준우 - 문제 제기한 시간을 어떻게 이용할지, 이를 이용해서 에러코드, 타입 narrow화


역할
데이터 전처리 1
EDA 1
피쳐 엔지니어링 2
모델링 (Tree-model, shap, bourta 등으로 feature selection 포함)

### 이때까지 한 것 

데이터 전처리
 - data type 변환
 - null 전처리

피처 preprocessing&generation
 - days feature 만들기
 - errorcode Label encoding
 - quality PCA using K-Means

모델링&스태킹
 - pycaret으로 자동 ensemble

### 진행 시 참고할만한 사항
Numeric Data - treebased model일때 feature scaling(minimax, std)에 영향을 받지 않음
Frequence Encoding - 지금처럼 user id fréquence encoding으로 진행시 최대 aux 0.85~6나올듯  - 뭔가 신선한 인사이트가 필요
quality 중 Null value가 많은 건 어떻게 다뤄야할지
quality 사용시 pca로 핸들링 했을 때 크게 작용하지 않음
특정 days와 errcode, errtype이 크게 작용함

### 데이터 고찰
- 오류는 분명 특이시점에 발생했는데 이를 무시하고 유저에게 오류가 발생했으면 전부 오류를 1로 치환한다? 그것은 조금 말이 안됌
- 사계열 데이터처럼 시간별 로그 기록이기 때문에 오류가 발생하기 이전에는 정상이였을 가능성이 있음
- 즉 오류가 발생한 시점 시간대만 1로 치환해보면 어떨까

## 2021년 1월10일
양희정
- 압축해서 상관관계살펴봄
- 특정 에러타입, 에러코드가 많거나 곂치는 게 있음
- 월,토,일이 생각보다 높음 (아마 많이 사용해서 그렇지 않을까 
	- 모델4와 상관관계가 있었다
- nf안드로이드2 ->넷플릭스 오류라서 티비 관련이지 않을까
- lgb, xgb로 돌리는 중
- 파라미터최적화 손볼 예정

윤준우
- 문제 데이터 살펴봄
- 문제 데이터 시간대를 사용해 문제제기 전을 1, 제기 후(프로그램이 고쳐졌다는 가정하)0으로 라벨링함
- 1200만개:400만개 정도로 적당하게 분포되어있음
- 16000개 데이터만 문제제기 시간 대 로그가 있음
- 라벨링을 새로해서 모델링 다시 돌려보고 인사이트 추출할 예정

이경수
- 퀄리티 살펴봄
- 유저,펌웨어,데이같은 경우 그룹바이로 해서 퀄리티를 평균화 해봄
- 관계파악에 집중해보겠음

정지영
- 라벨,피쳐 상관관계 봤는데 별로 높게 안나옴
- 군집화, 모델펌웨어 합친것, 날짜도 낮게나옴
- 퀄리티 11이 좀 높게나옴

## 2021년1월11일
이경수
- 퀄리티 데이터 핸들링 (같은유저, 같은날짜, 같은 펌웨어)
- 퀄리티 평균내서 대입하고 모델링 중
양희정
- 메모장에 적어놓으신 퀄리티, 에러 분석 내용
정지영
- 에러코드 군집화가 아닌 트레인, 테스트 곂치는거 로 진행
- 퀄리티 11만 사용
- lab, 튜닝한 후 0.831
윤준우
- problem 제기한 시간 기준으로 이전을 0, 이후를 1로 라벨링 해서 돌려봄
- 0.02 좋아짐
이지수
  - xgb,lgb, cat boost 스태킹해봄
- 2차평가 준비

## 2021년 1월 12일

이경수
- 필요없는 err column 제거
- 퀄리티 평균 값 넣어 모델링
- 그리고 로그 전체로 돌려봤는데 AUC이 99.9로 높았음 (아마 인덱스 넣어서 오버피팅)
- 테스트 데이터 형식에 맞춰야 해서 고민중임
- 퀄리티 데이터 없는 유저들 나눠서 돌려봄

윤준우
- 문제발생 이전과 이후로 나눠서 라벨링한 모델을 테스트 데이터에도 적용해봄
- 압축이 아닌 로그 자체로 모델을 돌렸고, 유저마다 특정 로그가 문제 로그일 확률을 구한 것이기 때문에  같은 유저안에 0과 1데이터가 둘 다 있었다 (0이 1대10 비율로 적었다)
- 유저아이디 기준으로 gropby 해서 확률을 모두 다 더하여 평균냈고, 이를 제출하니 0.5가 나왔다 - 전처리 문제가 아닐까
- 풀어야 하는 문제 자체가 유저가 문제 제기한 시간을 맞추는 것이 아닌, 유저가 문제를 제기 했는지, 하지 않았는지에 대한 binary classification문제이다.
- 즉 시간을 활용하려면 이전, 이후로 나누어 라벨링 하는 게 아닌 다른 방식으로 해야하지 싶다.
- 퀄리티 데이터도 평균내어 전부 넣어 모델링 해보았지만 결과가 좋아지진 않았다.

양희정
- err전체 카운트를 넣어봤는데 아직 돌리는중임!
- 피쳐 몇개 뽑아서 돌려봤는데 좋아진 것은 없음
- 피쳐 Selection (퀄리티)

이지수
- 2차 평가 준비
- 에러타입 간에 상관관계 분석

정지영
- 퀄리티 데이터 11만 사용
- 평균값, 표준편차, 군집 보고 넣어봤는데 효과는 없었음
- 퀄리티 


Todo
- 이경수: 퀄리티 데이터 없는 유저들 나눠서 모델 돌려보기
- 윤준우: 퀄리티 데이터 없는 유저들 특징 (유저타입, 코드, 펌웨어 등) 살펴보기
- 양희정: 퀄리티 데이터를 포함한 Feature selection, extraction
- 정지영: 퀄리티 데이터 없는 유저들 특징 + 어떻게 전처리하여 붙일지 살펴보기
- 이지수: 에러타입, 코드 추가 분석하기

## 2021년 1월 13일

양희정
- 1650만개 훨씬 안좋게 나옴
- 테스트 중
윤준우
- 퀄리티데이터 있는유저 없는유저 나눠서 피쳐들 돌려보니 0.893, 0.832나옴
- 퀄리티데이터 있는 유저들 퀄리티 넣어 돌려봤는데 0.8이였음
- 퀄리티데이터 있는 유저들에 퀄리티 피쳐(min,max,mean,var,std)를 넣어 돌려봤는데 0.8이였음
- 퀄리티 데이터 있는 유저들에 높은 importance를 가진 퀄리티 피쳐만 넣어 돌려봤는데도 그대로임
- 퀄리티데이터 피쳐만 가지고 돌려봤는데 이건 더욱 안좋음 0.76
- 결국 퀄리티 데이터를 피쳐로 쓸 것이 아닌, 유저를 세분화 시켜 따로 모델링하는 방향으로 가야할 것 같음
이경수
- 퀄리티만 따로 분석해보니 max,min,mean 큰 결과가 없었다
- 퀄리티가 있지만 문제제기안한 인원이 있고 퀄리티가 없지만 문제제기한 인원이 있다
- 퀄리티와 에러타입 관계
정지영
- 퀄리티 데이터 최소,최대,분산 등을 사용해봤지만 별로 안좋아짐
- 피어슨, 피어만 상관관계를 이용해 퀄리티 데이터 전처리 해봄
- lab, catboost돌려봤는데 
- 모델별로 유저 나눠서 시도해보고 싶음


방향
- 퀄리티 데이터를 기준으로 유저를 나눈다
- 에러타입 기준으로 유저를 나눈다
- 에러코드 기준으로 유저를 나눈다
- 펌웨어를 기준으로 유저를 나눈다

- 15000개로 압축해서 진행한다
- 1600만개 데이터를 전부 사용한다

## 2021년 1월 13일 - 퀄리티 데이터 분석 요약
퀼리티 데이터 분석

user_id
퀄리티를 가지고 있는 유저 수: 	유저 15000명 중 8281명 (1600만개 중 580만개 로그) 
퀄리티를 가지고 있는 유저 분포: 	고름
각 유저의 퀄리티 로그 수  분포
	로그 수 4224~100: 1428명 (17%)   100~12 6853명 (83%)
	로그 수 4224~100: 문제제기 53%    100~12 문제제기  39%
	mean      100.063277	std       269.316318
	min         12			50%     24
	75%        72			max      4224

fwver
펌웨어 수: 전체 37개 중 28개 	하지만 전부 triain_error에 분포가 높은 펌웨어이다
펌웨어 분포:  상위 7개 펌웨어가 93.7%의 퀄리티 데이터를 차지한다 - train_err에서도 동일
	05.15.2138    163236		04.22.1750    142032
	04.33.1261    131340		04.16.3553     111996
	03.11.1167     104148		04.33.1185      66024
	04.22.1778     56472		04.22.1684       3420

time / day
요일 수:  		같음
요일 수 분포:	0(216) 빼고 골고루 분포되어있다.	train_err도 마찬가지(0,31,32 해당)
시간 수: 		같음
시간 수 분포:	골고루 되어있음 - 비교적 아침 시간대 3~11시가 로그수(사용량)이 적다

Quality 0 		-1 ~ 157667	754	결측값 (144432개)
Quality 1 		-1 ~ 171		31	
Quality 2 		799 ~ 191859	결측값 (40113개)
Quality 3 		전부 0
Quality 4 		전부 0
Quality 5 
Quality 6
Quality 7 
Quality 8 
Quality 9 
Quality 10 
Quality 11

1. 퀼리티 7/8/9/10/12 번은 같은 시간대에 무조건 한개의 값을 가진다. (여러행이라면 같은 값)
2. 퀼리티 0~12번 데이터 값중 -1이 있다면, 퀼리티 0/1/2/5/6/11 은 전부 무조건 -1값이다.
3. 퀼리티 3/4번 데이터 값은 전부 0이다.
4. 퀼리티 데이터 값 중 -1 값은 0/1/2/5/6/11번 퀼리티에만 있다.
5. 결측값은 퀼리티 0(144432개) / 2  / 5(20개) 에만 있다.
6. 퀼리티 0번과 2번의 상관관계를 매우 높을것으로 예상되며, 서로 같을 값일 확률이 매우 크다.
7. fwver 8.5.3 / 10 일 경우, 퀼리티 0과 퀼리티 2의 데이터는 수집되지 않는다.
8. fwver 03.11.1167 / 03.11.1149 일 경우 퀼리티 0번 데이터만 수집되지 않는다. (퀼리티 2번 데이터는 수집됨)
9. 퀼리티 5번 데이터값이 결측값일때, 퀼리티 10번의 데이터 값이 매우 크다.
10. 퀼리티 11번의 데이터 값이 1이라면, 퀼리티 12번의 데이터값은 무조건 1 이상이다.
11. 퀼리티 11번의 데이터 값이 1 이상이라면, 퀼리티 5/10번 데이터 값이 매우 큰 경향이 있다.
12. 퀼리티 10번의 데이터 값이 크다면, 퀼리티 5번의 데이터값이 큰 경향이 있다. (5번과 10번의 상관관계가 커보인다.)

에러데이터 분석
1. fwver == 10 일때, 에러코드는 전부 문자열값이다. 		B-A8002 /S-61001 /C-11017 /U-81000  /V-21003 /V-21007/ V-21008
2. fwver == 8.5.3 일때에도 에러코드는 전부 문자열 값이다. 	B-A8002 /S-61001 /M-99999  /V-21008
   또한 fwver 10/ 8.5.3 버젼은 모델6에만 있다. (모델 6번이 최신형 기기일 가능성이 높음)
2-1. 다만, 낮은 버젼의 fwver 에서도 문자열 에러코드값은 존재한다.
3. fwver 05. 이상 버젼은 모델 3, 7번에만 존재한다.
4. errtype 5 의 경우 errcode 는 거의 대부분 문자열 에러값.
5. errcode -269 데이터 2건은 아웃라이어 데이터같음.

## 2021년 1월 14일
이경수
  - 퀄리티 측정한 유저만 둘려봤을 때 0.8
- 퀄리티 측정 안한 유저만 돌려봤을 때도 0.8

정지영
 - 모델별로 분류하여 돌려봄
- 0,1,2는 0.83정도로 괜찮았는데 0.7후반대였음

윤준우
- EDA 전체적으로 정리해봄
- 퀄리티 있는 유저 없는 유저 0.825나와서 튜닝중
- 전체 로그로 돌려봐도 0.8이라 압축하나 안하나 비슷함

일단 각자 하는 분야를 더 살펴보고 좋은 결과가 나오지 않을 시 

좋게 나온 모델들만 가지고 모델링을 하던지 앙상블을 하던지 하고

각자 역할분담하여 진행하면 될듯함


submission = model1*0.3 + model2*0.4 + model3*0.2 + model4*0.1
AUC 잘나오는 순서대로 가중치를 두던지, 아니면 val set을 만들어서 가중치 자동화


데이터 leakage 찾기
- 케글하고는 달리 dacon은 첨부된 test data 중 일부를 나눠 private, public으로 나눠 점수를 메기기 때문에 테스트 데이터는 꼭 추론에서 사용하라 한다
- 즉 테스트 데이터에서 트레인 데이터에 중복된 값이나 패턴을 찾아낸 뒤 이를 활용하면 될 것이다 (물론 코드에는 안 보이게 할 것)
Time series 데이터 활용
- 사실 time series 데이터지만 이를 활용하고 있지 않음
- 시간별로 묶거나, 같은 시간 내 변화량, 같은 량 등을 피쳐 엔지니어링으로 만들어보자
- 문제가 발생한 시점을 기준으로 시간 차, 변화량 등을 사용해도 좋을 것이다
- 문제를 제기한 시간을 줬다는 이야기는 이를 기준으로 나누던가 활용하라는 이야기가 아닐까
피쳐 엔지니어링 작업
- 최대한 피쳐를 많이 뽑아내야한다
- 피쳐를 우리가 고르는게 아니고 최대한 여러 피쳐와 여러 모델을 통해 메타 모델링을 할 예정이기 때문
- 단 정말 쓸모없는 피쳐나 중복된 피쳐는 고려해보자 (quality3,4 예)

메타 모델링 기법 사용 
모델 1단계
lightgbm, catboost, gbc, rf, et등 최대한 많은 모델 수행 
- 각각 여러 변수들을 넣고 빼고 하여 만든다
- 예시) errtype, errcode 만 넣은 lightgbm
- 예시) model, days, errtype만 넣은  cat boost
- 얘시) model0,1,2,3,4 로 나눈 lightgbm

모델 2단계
prediction이나 auc이 잘나오는 모델을 선정해 5-fold bagging/stacking XGB를 실행해 최종 모델을 만든다

## 2021년 1월 15일
이경수
- 퀄리티있는 유저 없는 유저 나눠서 돌려보는중

윤준우
- 데이터 leakage, 중복값 찾음 -코드참조

정지영
- 모델, 펌웨어 나눠서 해봤는데 0.76
- 0.83에 hour feature, tuning 해봤는데 더 안좋아짐
- 상관관계 극대화 시켜보면 어떨 것 같은지 - error importance feature 넣어봤는데 그리 좋아지지 않음

이지수
- 품질 변화에 따라 어떻게 문제제기를 하는가
- 시간별 데이터를 고려해봐야하지 않을까 - 시간별 변화량에 따라 문제제기를 했냐 하지 않았느냐를 물어보는 것 같다

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
데이터 leakage 찾기
- 케글하고는 달리 dacon은 첨부된 test data 중 일부를 나눠 private, public으로 나눠 점수를 메기기 때문에 테스트 데이터는 꼭 추론에서 사용하라 한다 (케글은 오류없는 코드를 제출하고 그 코드에 숨겨둔 test 데이터를 돌려 public 점수를 매김)
- 즉 테스트 데이터에서 트레인 데이터에 중복된 값이나 패턴을 찾아낸 뒤 이를 활용하면 될 것이다 (물론 코드에는 안 보이게 할 것)
Time series 데이터 활용
- 사실 time series 데이터지만 이를 활용하고 있지 않음
- 시간별로 묶거나, 같은 시간 내 변화량, 같은 량 등을 피쳐 엔지니어링으로 만들어보자
- 문제가 발생한 시점을 기준으로 시간 차, 변화량 등을 사용해도 좋을 것이다
- 위 두가지 방법을 다른 대회 상위권 유저들이 많이 사용함
- 문제를 제기한 시간을 줬다는 이야기는 이를 기준으로 나누던가 활용하라는 이야기가 아닐까
피쳐 엔지니어링 작업
- 최대한 피쳐를 많이 뽑아내야한다
- 피쳐를 우리가 고르는게 아니고 최대한 여러 피쳐와 여러 모델을 통해 좋은 auc 모델 메타 모델링을 할 예정이기 때문
- 단 정말 쓸모없는 피쳐나 중복된 피쳐는 고려해보자 (quality3,4 예)

메타 모델링 기법 사용 
모델 1단계
lightgbm, catboost, gbc, rf, et등 최대한 많은 모델 수행 
- 각각 여러 변수들을 넣고 빼고 하여 만든다
- 예시) errtype, errcode 만 넣은 lightgbm
- 예시) model, days, errtype만 넣은  cat boost
- 얘시) model0,1,2,3,4 로 나눈 lightgbm

모델 2단계
prediction이나 auc이 잘나오는 모델을 선정해 5-fold bagging/stacking XGB를 실행해 최종 모델을 만든다

윤준우
Kaggle - <생산 라인 전 과정에서 시간별로 수집된 복잡한 데이터를 기반으로 불량품 탐지> 대회 참조

1등
- 2주를 eda하는데 보냄 - feature끼리 카운팅, 확률,  상관관계 등 어떻게 설명해주지 않은 feature들을 이용할지 고민함 - 우리기준 quality
- 특정 feature별로 ordering 해서 feature을 뽑아냄 - 로그 숫자 등
- 시간 feature을 많이 만들어냄
        - 다음 2.5, 24, 168시간마다 로그 갯수
        - 같은 분 내의 로그 갯수
        - 최근 문제 제기와 시간 차이
        - 다음 문제 제기와 시간 차이
- 범주형 데이터를 처리 할 때 너무 많으면 크게 영향을 끼치지 않는 몇개는 군집화 함
- 4 FOLD "leak-stratified" CV (forcing to have the same number of duplication for each fold) 를 사용했다는데 어떤게 same number of duplication인지 이해가 안감
- 0라벨링은 다운샘플링함 

3등
- 동일한 수치형 데이터를 가진 특정 데이터 값들이 높은 비율의 불량으로 이어지는 것을 사용함
- 각 모델/펌웨어에서 동일한 날짜, 시간대에 실행되는 값을을 모아 새로운 변수를 추출함
- 저희는 모든 모델/펌웨어별 시작일부터 종료일 기준으로 산출한 문제제기의 이동 평균을 기반으로 모델을 학슥함
- 트리 기반 모델이 쉽게 추출하지 못하는 데이터의 래그(lag) 값 등을 추가함
- 일반적인 피쳐 엔지니어링도 이용
        - 범주형 변수를 Bayesian 평균 값으로 인코딩 
        - 범주형 변수, 날짜 변수 및 수치형 변수의 고유 값 개수 
        - 모델과 펌웨어가 어떻게 변경된지 인코딩한 값 
        - 행별 수치형 변수 내 NA 개수, 모델/펌웨어 별 최대/최소 값
- 1차 모델로 lightgbm, et, nn, rf, linear 등 160개 모델 사용
- 모델 선정 후 좋은 모델들만 xgboost bagging
- 1차 모델 과반수 투표 기법 + 2차 모델로 제출

4등
- 비슷한 열이 얼마나 있는지 더해서 넣음
- 섞어서 메타 모델링 -> 메타 피쳐와 문제가 있는 데이터만 모델링 -> xgboot, rf, et, kr해서 평균해서 넣음
		
7등
- 중복된 열만 골라서 훈련함 - N, N+1열이 비슷했다
- 문제가 N열에 있을 시 N열과 붙어있으면서 비슷한 열만 1로 라벨링 나머지는 다 0으로 하였다
- 다른 feature들
        - 특정 시간대로 나눈 그룹에 얼마나 많은 열이 있는지
            - 열이 엄청 많거나 엄청 적으면 문제가 있고 (1) 딱 중간 정도가 있었으면 (0)일 확률이 높았다
        - 특정 시간대는 다른 시간대 보다 문제가 생길 확률이 높았다 -> proximity by time (시간이 근접한지) 이 중요한 feature이였다
        - 시간대에 따라 얼마나 열 값이 유지되는지
        - 특정 행은 특히 중요하여 원핫 인코딩을 하였다
        - 문제있는 N열 다음. 또는 이전(N+1, N-1)열 들의 특정 행이 중요하게 작용하였다 
        - 지금 중복되는 부분이 어딘지 적었다 (총 유저 아이디에서 4개 그룹으로 나눠 중복된다 하였을 때 지금 열은 3번째 그룹)
        - 조금이라고 더 올리기 위해 한달동안 만든 모델들을 다 합쳐 메타 모델링을 사용했다 (xgb max_delta_step=1.5)
            - 만든 모델들의 확률들을 사용해 그게 1/0을 예측하는지 사용
7등에서 나온 인사이트
- 라벨링을 문제가 생긴 범위 주위만 해보자
- 전체 데이터 셋이 아닌 범위별로 나눠서 해보자 - 테스트 데이터도 같게 나누면 상관 없다
- 비슷한 수치형/시계열 값을 가질 경우 동일한 문제 발생하는 그룹에 포함되어 문제 발생 확률이 유사할 것 (leakage 사용법)
- 시작시간과 id를 기준으로 순서대로 나열한 다음, 다음 열이 같으면 1 아니면 0? 

8등
- 1차 - lgbm, xgboost, rf, nn을 5개 데이터 셋으로 나누어 실행했음
        - 데이터 세트 1 (0.477 lgbm) - 순서, 숫자형 데이터, 날짜, 범주형 자료
        - 데이터 세트 2 (0.482 gbm, 0.477 xgb, 0.473 rf): 순서, fwver, 숫자형 데이터, 날짜
        - 데이터 세트 3(0.479 gbm, 0.473 xgb) : 순서, fwver, 숫자형 데이터, 날짜, 정제한 범주형 자료
        - 데이터 세트 4(0.469 xgb, 0.442 rf) : 숫자형 데이터 / 날짜 /  최근접이웃탐색(L1 맨해탄, L2 유클리디안 거리) 별로 sorting
        - 데이터 세트 5(0.43 xgb) : fwver,  최근접이웃탐색
- 2차 - 위 모델에서 나온 예측값과, 데이터셋5, 몇몇 feature 사용
- 30% 2차 xgb(0.488)과 70% rf(0.485) 스태킹함
- feature engineering 예시들
        - 시간별로 차이, kurtosis
        - lead lag feature generation  -> 특정 그룹id와 날짜/시간 기준으로 정렬(sorting)을 해놓은 다음에, lead() 나 lag() 함수를 가지고 행을 하나씩 내리구요, 직전 날짜/시간 대비 이후의 값의 변화, 차이(difference)를 구한다
    - 마지막 합칠 때 여러 제출 파일들을 4fold로 variance 측정한 뒤 OOF로 AUC, threshold, positive rate, true positive, false negative 측정해서 결과가 최대한 비슷한지 살펴봄
￼
￼
## 2021년 1월 16일
이경수
- 휴대폰 로그로 광고인지 아닌지 판별하는 대회 코드 살펴봄
- 불균형 데이터 - 다운샘플링) class imbalance 살펴보자
- (변화랑)비율, 카운트, 시간 고려해서 많은 feature 만든 다음 메타 모델링 실행
- PCA / LDA로도 feature 만들어봄
- rnn lstm +시간 고려해보자
- 시간별로 짤라서?
- 행렬분해 - 우리가 하고있는 것
- 정규화 시도 해보기

양희정
- 에러타입*데이 = 42*31 -> 1200개 해서 돌려보니 그대로
- 캐글로 참조해봐야 할 것 같음

윤준우
- 퀄리티의 특정 패턴이 어떻게 문제를 야기시키는지 보고있음
- 퀄리티 데이터만 가지고 훈련중이며 문제가 발생한 시간만 1로 라벨링해서 보는 중 - 문제가 발생하기 전에 특정 패턴을 가지면 1로 바뀐다를 찾고있음
- 캐글 대회 리뷰
- 상위 유저들은 전부 메타모델링 사용 (변수별로 그룹화하고 특정 데이터별로 그룹화 해 모델링 -> 잘나온 모델들만 배깅으로 2차 모델링) - Parameter Set 0…i, Data Set 0….i로 나눠서 총 i! * i! * 모델개수별로 수행했다고 함
- 설명되어지지 않는 데이터 (우리 기준 퀄리티)를 카운팅, 확률,  상관관계 등을 사용해서 최대한 패턴을 찾아내거나 해석해보려고 시도함
- 시간별로 데이터를 그룹화하거나, 같은 시간 내 변화량, 같은 량 등을 피쳐 엔지니어링으로 만듬 - 다음 2.5, 24, 168시간마다 로그 갯수, 같은 분 내의 로그 갯수 등
- 우리 기준 모델, 펌웨어, 에러코드,에러타입이 시간별로 변화하는데 이를 이용했다고 함 time series lag function이라고 하는데 공부 필요
- 동일한 수치형 데이터를 가진 특정 데이터 값들이 높은 비율의 불량으로 이어지는 것을 사용함 => 특정 패턴이 높은 확률로 불량
- 중복된 열이 많아 이를 그룹화 함 - 문제생긴 시간대의 앞 뒤 그룹을 살펴봄
- 문제있는 N열 다음. 또는 이전(N+1, N-1)열 들의 특정 행이 중요하게 작용하였다
- 시간별 데이터 차이) kurtosis, 시간별 바뀐 정도, lead lag feature generation 등을 사용하였다

정지영
- test set에 없는 퀄리티 데이터 범위를 train set에서 삭제시켜서 학습시켜보았고, 
- 2. 모델 변경 이력이 있는 유저를 체크하는 model_change 변수를 생성해서 학습시켜보았고 
- 3. 혹시 모델별로 치명적인 에러타입이 있을지 확인해보기위해 모델번호+에러타입을 합쳐서 파생변수를 만들어, 269개로 라벨인코딩 후 더미변수로 만들어 학습시켜 보았습니다. 
- 아직 submission6보다 AUC가 향상된 결과가 없으며, 
- 준우님이 올려주신 캐글대회의 고득점 노트북을 검토하면서, 새로운 파생변수 생성(시간을 활용하고 싶은데, 아직 아이디어가 없네요)이 성능을 올리는데 가장 좋을것 같다고 생각합니다

토론)
분포적인 측면, 파생변수 측면, 그룹방식으로 나누는 측면 으로 시간 데이터는 사용해봐야하지 않을까

~(수) 전처리, 파생변수 생성

~1주 모델링

~1주, 최적화 및 2차

## 2021년 1월 16일 - 본인 아이디어
아이디어

과연 문제 제기를 17일 21시에 했으면 1일 7시 데이터와 연관이 있을까?
- 날짜별로 32번 돌리면 output 어떻게 묶을래? - 전부 더해서 평균? 0은 전부 평균, 1이 있으면 가장 높은 확률로?

시간대별로 변화량 찍고 문제시간 보면 답 나오지 않을까?

우리가 하고있는 것 에러가 몇번 나타났는지만 가지고 예측하고있다 - 언제 문제가 발생했던 문제 발생 여부만 확인하면 되어서
펌웨어 1 -> 펌웨어 3 -> 펌웨어 2 와 같이 변화에 대한 인코딩이 없다

이상치와 정상데이터가 곂치는 부분은 0 아닌 부분은 1로 카운트해서 넣어보자



▣ 문제분석 및 해결과정 소개
1. 정상과 불량 구별하는 데이터 특징 찾기
2. 비대칭도(Skewness)를 이용한 비정상 데이터 찾기
3. Support vector machine 알고리즘 적용
4. 데이터 정규화(normalize) 및 딥러닝 알고리즘 적용(binary classification)
5. 시간별 누적 이상치를 바탕으로 한 실시간 불량 감지		



3가지 종류의 이상치가 있다
1. Point anomalies: 한 곳이 다른 곳이랑은 완전 다르다 -  갑자기 1억을 출금했을 때 time interval [Xt−k, Xt+k], k ∈ R에서 봤을 때 매우 큰 출금액이다  
2. Collective anomalies: 한 곳이 이상한 것이 아닌 패턴 자체가 이상치이다 - 1일에 50만원을 출금하는 것은 정상처럼 보이지만 매시간 50만원 출금하는 것은 이상이 있다고 판단한다
3. Contextual anomalies: 맥락에 따라 다르다 (feature간의 상호작용이 아닐까… 예로 들면 퀄리티 1이 10일때는 정상이지만 퀄리티 1이 10이지만 5가 1000을 넘어가면 이상이 있다) - 한국 여름 날씨가 28도일 때는 정상이지만 겨울에 28도이면 문제가 있다

-problem data에 주어진 시간이 퀄리티에 대부분 없음 5000명중 124명만 존재

-problem data에 주어진 날짜가 존재하는 데이터도 5000명중 560명 밖에 없음


## 2021년 1월 17일
이경수
- days, hour 돌려봤는데 0.817
- quality mean 정규화 0.002 증가 - 퀄리티 없는 사람 기준 => 0으로 들어감
- 파생변수 생성해봐야하지 않을까
윤준우
- tsne로 차원축소해서 퀄리티 데이터에서 문제가 있는 패턴을 나눠보려했는데 잘 나눠지지 않음
- auto encoding으로 시계열 분석했는데 0.65로 나옴
- problem data에 주어진 시간이 퀄리티에 대부분 없음 5000명중 124명만 존재
- problem data에 주어진 날짜가 존재하는 데이터도 5000명중 560명 밖에 없음
- 위에 따라 퀄리티 데이터를 시간별로 사용하는건 어렵지 않을까 싶음
양희정 
- 캐글을 살펴봤는데 비슷한건 찾지못했다
- 날짜별로 퀄리티, errtype column 치환해서 돌려볼 예정

정지영
- lstm 해봤는데 0.77정도였음
- 0아니면 1로 카운트해서 퀄리티데이터 적용해서 모델링 해봤음

이지수
- 에러 ->  문제제기  -> 퀄리티 측정으로 되어있다 
- 펌웨어에 따라 에러타입이 어떻게 달라지고 이게 라벨링에 어떻게 영향을 주는지 살펴보고 있었음


## 2021년 1월 18일
이경수
- 파생변수 생성을 위해 변화량을 구하려 하고있음
- 문제제기하기 전의 user_id만 돌려보기 - 실수함
윤준우
- 퀄리티 'mean', 'max', 'min', 'std', 'var', 'count’ 넣으니까 올라갔다
- 다음 (1,2,3,4,5)열과 퀄리티 값 차이, 시간차이, 날짜차이를 넣어 총 510개 파생변수 만들었고 모델링으로 확인해볼 예정
정지영
- 벨류카운트를 통해 퀄리티 가중치를 어떻게 더할지 생각중
- 모델+펌웨어 해볼예정
이지수
- 2차 3번 하는중 
- 에러 데이터와 에러간 관계해석

## 2021년1월19일
이경수
- 3차원등 이것저것 시도해봄
윤준우
- 퀄리티 파생변수 400개 생성하여 총 2000개 변수로 돌려봄 (가장 높은 점수)
- lgqbm feature importance 로 중요한 200개 변수만 골라봄
- 에러타입, day가 상위권이고 추가로 넣은 퀄리티 파생변수 가 주요하게 작용함
양희정
- 에러타입과 날짜 3차원으로 만들고 2차원으로 펴보니 0.7
- 여러가지로 시도해봄
정지영
- 제일 숫자가 적은 0번 군집화만 하고 에러코드 군집화
- 군집화 시간이 많이걸림
- 안곂치는것 0번으로

## 2020년 1월 20일
이지수
- 관계해석은 모델링이 끝나고 해야하지않나 싶어서 제일 잘나온 모델 돌림
- 회귀분석으로 돌려서 퀄리티 데이터 확인해봄
- 2차 대회 준비 및 다른 대회 ppt 찾아 올려봄

정지영
- 날짜 기준 바꿈 (10월 12월)
- 펌웨어 말고 모델이 나은 것 같음
- 기존에서 에러코드 군집화 + quality 피쳐 추가해서 하는중

이경수
- 크리티컬한 에러타입 보려고 해봄 - 연관분석
- association based feature / classification model 사용하면 좋을 듯
- 공부할 예정

양희정

윤준우
-각 유저별 시간vs에러타입, 시간vs에러코드를 찍어봤다
    - 특별히 전,후로 에러타입이나 코드가 변경된 것은 보이지 않음
    - 문제제기할 때 특이한 값을 가지고 있는 것도 아님
    - 한가지 발견한 것은 특정한 에러타입이나 코드만 반복된다는 것
- 에러데이터로 변수 만듬
- 주요한 에러타입은 추가적으로 원핫인코딩 후 변수 추출
- 통 2300개 변수 (1400개가 에러코드)로 진행 중

역할분담
EDA (수치해석,관계해석 등등) 및 2차 위주로 분석 - 양희정 이경수 이지수
Feature enginnering 및 모델링 - 정지영 윤준우 

## 20201년 1월 22일
이경수
- 상관관계 분석 가능한 형탤 바꿈
- 지지도 신뢰도 향상도 중 
- support 설정 후 라벨과 관계있는 에러 찾아보고있음

정지영
- 자주 등장하는 변수만 변화량 트래킹해서 변수 만듬
- 퀄리티도 마찬가지
- train - val 사이즈 다르게 해서 모델링중

윤준우
- 상위 500개 변수 뽑아서 돌리는 중
- 파이케럿말고 싱글 또는 수동 모델 블랜딩 하는중

## 2021년 1월 21일
이경수
전 일정 이상의 지지도, 특정 개수 이상의 itemset(ex) err10,err11)만 도출 후 지지도 확인,  특정 itemset이 포함된 것만 추출, 신뢰도 및 지지도가 특정 숫자 이상인것만 추출, 상호 정보량이 가정 큰 것 추출, 다중 조건일 경우 향상도 젤 작은것 추출 등등 보면서 유의미한게 있는지 찾아보고 있고 오늘은 시각화도 한 번 해볼생각입니다

정지영
저는 에러타입 / 에러코드 / 퀄리티별로 가장 많이나온 3가지를 기록하는 변수랑 그 3가지의 패턴을 기록하는 변수를 만들고있어요. PCA는 원본 데이터 설명력 99.9%로 가져와도 성능이 많이 떨어져서 차원축소는 더이상 진행안하고있어요.

윤준우
저는 std var mean median quantile(10%, 25%, 75%, 90%) min max로 시계열 lag, rolling 변수 (다음칸과 얼마나 차이나는지), 중요한 에러타입은 원핫인코딩해서 돌리고 있고 테스트 데이터도 만들고 있어서 다만들면 모델 돌려서 제출해볼 예정입니다

## 2021년 1월 23일

윤준우

전처리
- NaN값 처리 - fillna(0)
- skewness 처리 - box-cox transformation
￼
- memory reduction - bumpy int, float64->32,16 으로 줄여서 메모리 사이즈 축소


Feature selection
1. correlation threshold로 drop 하기 (0.95 or 0.97)
2. lightgbm으로 모델링 후 feature importance / Shap 으로 상위 변수 골라내기
3. permutation importance 로 변수 골라내기 
       (모델링 후 하나의 열을 골라 무작위로 섞어보고 결과가 떨어지는지 보기 - 많이 떨어지면 그 변수가 그만큼 많이 중요하기 때문에 떨어진 것) 
￼
	방법 1: 3400개 // 2-> 2000개  // 1(0.95)-> 약 1300개 // 3-> 1~200개
	방법2:  3400개 // 2-> 500개 // 1 (0.97-> 약 400개 // 3-> 1~200개 (


Modelling (OOF 생성하기)
1. OOF란 특정 모델에서 나온 train/test prediction 결과라고 보면 된다 k-fold도 oof 중 하나 (validation을 다르게 나뉘어 평균내기때문)
2. Lightgbm + Cat + XGB + GBC + ET/RT => 50~100개 생성
3. 위에서 생성한 모델중 auc 0.83넘는 모델만 OOF, 중요한 변수 50개 정도만 골라서 2차로 XGB, LGB, CAT Bagging -> 제출

이경수
- 에러데이터 수치해석 (threshold 다르게보기)
- 퀄리티 데이터 붙여서 해석 예정
- 

정지영
- mlp 돌려봤는데 성능이 안좋음
- 군집화해서 다시 해보는중 


## 2021년 1월 24일
양희정
- skitoplot으로 이상치 정리
- 퀄리티 값 저장 누적치로 변경 후 0.002 상승 
- mean 값으로 계산하고 이를 변수로 생성 - 조금 상승
- 트레인 에러+코드 합쳐서 원핫인코딩 하는중

이경수
- 지지도를 이용한 상관관계 
- 지지도 높은 것들만 모델 돌려봤을 때 0.77 (drop duplicate)
- 위에서 중복제거 - 0.795
- 퀄리티 넣고 중복제거하니 0.798

정지영
- 에러타입 발생빈도수 (펌웨어, 모델과도 합쳐봄) 0.819
- 중복제거해서 해볼 예정

윤준우
- stratifiedkfold (k=2,4,5,6), novelization 이 0.831~0.834로 좋았다
- seed를 섞어서 평균내기, column을 섞어서 feature fraction으로 떨어트리기 한 후 평균내면 overfit방지
- quality density 를 보니 문제가 있다고 신고했을 때 보통일때의 퀄리티 값의 density가 낮아지고 특정 값들의 density가 올라갔다 (std 가 낮아졌다 생각하면 될듯) - 관계분석시 사용
￼
    - 제출한 것들 중 제일 잘나온 모델의 라벨 분포도를 봤더니 많이 부족하다
        - 모델이 확실하지 않다는 이야기고, 가운데 확실하지 않은 값이 많아질수록 auc이 떨어짐
￼

## 2021년 1월 25일

정지영
- 중복제거, 카운트, 군집화 사용해서 0.8319
이경수
- train_err은 시간포함 중복제거, quality는 month, day빼고 중복제거 - 베이스라인과 0.007 차이남
양희정
- 에러타입 38번이 데이터 수는 적은데 에러코드가 엄청 많아 이건 전처리
- 나머지는 에러타입, 에러코드 묶어서 200개 정도 변수 생성 -> 원핫 인코딩
- qmean 값 추가 
- 
윤준우
- train quality가 test랑 완전 같은 경우 train데이터의 problem 을 이용해 test데이터 값을 일부 변경했는데 오히려 낮아짐
- pipe라인 구성함 (limb feature imp (5kold * 20회반복) -> grid search 최적화)  
- 
이지수
- adversarial validation 실행중


## 2021년 1월 26일
이경수
 - kaggle 에 올라온 eda 살펴봄
- 이를 토대로 관계해석 할 예정임

윤준우
- ngram으로 에러타입 변수 만들어봄
- 모델링 계속하고있지만 val 0.83~84
- 정답 밀도 그래프를 보면 0.4~0.6 사이에 애매한 것들이 많은데 어떻게 잘 구분할지

이지수
- adversarial validation 실행중


## 2021년 1월 27일

이경수
- 문제가 발생하여 문제를 제기한 것임
- 무의미한 에러 타입이 계속 반복하여 나오는 경우는 필요없다 생각하여 문제제거
- 문제 발생한 유저, 그리고 문제 발생하기 전만을 살펴봄
    - 특정 errtype value count하여 자주 등장하는 빈도수만 훈련 
정지영
- 에러타입, 에러코드 등장한 유니크 갯수 
- 훈련해봤지만 train 데이터는 점수가 좋은데 검증 점수가 안좋다

양희정
- 에러타입 에러코드 묶어서 원핫 인코딩으로 변수 생성
- 모델, 펌웨어 넣으니 lgb 0.82, 에러타입-코드-모델도 묶어 원핫인코딩 생성 예정

윤준우
- 변수 약 3800개 csv파일 정리하여 드라이브 업로드
- 변수 고르고 중요도 확인하는 코드도 정리하여 업로드
- 모델 파이프라인 작업중

이지수
- 이때까지 한 것 정리 및 추가적으로 관계해석 정리해놓은 것 업로드
- 파생변수 아이디어 생각해볼 예정


문제가 생긴거 안생긴것을 맞추는게 아닌
제기 했냐 안했냐를 테스트하는 것이다

시스템에서의 문제가 아닌 사람이 느끼기에의 문제


## 2021년 1월 28일

정지영
-에러타입 38번을 빼고하고있음
- 39번 빼면 에러코드가 2000개 넘게 빠진다

양희정
- 모델까지 추가해서 원핫인코딩 - 안좋아짐

이경수
- 가중치 둬서 하는 건 크게 오리지는 않는다
- 오토인코더 돌려볼 예정

윤준우
- 메타 모델링 파이프라인 코드 작성
- 변수 추가해봤지만 추가한 변수들은 그렇게 큰 결과는 주지 않았음

이지수
- 펌웨어 퀄리티 관련이 있을 것 같아 살펴봄 (묶어서 실행해볼 예정)
- 에러데이터에서 패턴이 문제 발생에 상관관계가 있을 것 같아 결과해석에 참고

## 2021년 1월 29일

정지영
- 시간차 변수 생성

이지수
- fw, model count 구현

윤준우
- retype 주,일,시간별로 카운트하고 mean, std로 변화량 변수 생성

## 2021년 2월 1일
정지영
- 윤준우, 이지수, time diff, wdh, fever, time diff 변수 등등 사용하여 0.846
- 추가적으로 적용할 데이터 더 있음
이경수
- ppt, 관계분석, 수치해석 중점
- 어떻게 진행되고있는지 따라가는중
- 변수와 스토리텔링 디테일하게 필요
윤준우
- 시간관계 변수 추가 생성 (특히 퀄리티)
- 퀄리티 관련 시간 고려 변수 추가 생성
- 스태킹으로 모델 추가해서 마무리할 예정
이지수
- 2차 준비로 넘어가서 경수님 서포트 및 해석
- 도움이 될만한 변수가 있음 확인 후 이야기


## 2021년 2월2일

이경수
- pt준비
- 2차대회 분석, 이전 대회 참조, 스토리텔링 구성
정지영
- 여러가지 변수 넣고 빼고
- 펌웨어 원핫인코딩 및 시간 고려 변수 추가해서 하는중
- 이때까지 만든 데이터 변수 설명 및 정리
윤준우
- 정지영님 데이터 / 정지영님데이터+퀄리티0131 두가지로 진행중
- 스태킹도 시도하고 있지만 시간이 많이 걸리고 하이퍼파라미터 튜닝해야해서 진척이 별로 없음
- 0.845가 최대라 신중히 제출해봐야하지 않을까…
- 데이콘 토론글 읽어보기

