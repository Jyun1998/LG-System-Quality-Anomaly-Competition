## 2021년 1월 7일

윤준우
- 데이터 preprocessing
- 데이터 EDA 
이경수
train quality feature selection
- train_err 변수 상관관계 (변수형이기 때문)
- model - error type 43%
- fever - error type 20%
- error type - err code 50%

이지수
- 베이스라인만 실행해봄

정지영
- error code 군집화로 트레인 돌리기
- pca=3 으로 0.05정도 상승

양희정
- 베이스라인 실행해봄
- 일별 합산 데이터 추가 해서 돌려봄
- 일별로 errtype 추가 중  

Todo
- 데이터, 빙향성 살펴보기
- 주말에 각자 역할정하기 (Preprocessing, EDA, Modeling, Fine-tuning&Ensemble)


## 2021년 1월 8일

이경수
- 차원축소는 별로 효과가 없다
- 모델이랑 펌웨어랑은 상관관계 거의 1
- errtype고려하면 그저 그럼
- 

정지영
- 코랩 쉐어 파일
- pca로 군집화 하여 실행시켜봄

윤준우
- 코랩 쉐어 eda 
- train_prob살펴봄
- days를 넣으면 auc 0.15오름 

이지수 
- 모델 스태킹해봄

단체토론
- 퀄리티 데이터란 무엇인가…?
-      시스템 퀄리티 로그
-      NaN value가 많은 퀄리티도 있음
-      퀄리티 3,4 는 아예 전부 0임
-      원론적으로 퀄리티 로그가 무엇을 뜻하는  지 예측해봐야 문제를 풀 수 있지 않을까
- 단순하게 모델링에 집중하면 당장은 점수를 올릴 수 있지만 인사이트가 필요함

TODO
- 각자 코드 완성해서 올려놓기
- 인사이트 도출해보기
- 데이터 살펴보기

## 2021년 1월 9일

양희정
- time, user 아이디빼고 펌웨어,모델 살펴봄
- 같은 유저아이디 기준 펌웨어, 모델은 같다
- errtype 원핫인코딩 예정
윤준우
- Feature importance 로 중요하고 크리티컬한 feature을 추려봄
-    모델 2,3번 / errorcode 0, 2, 3 terminate by peer user 그리고 많은 errtype과 days가 중요했음
- errcode는 크게 모델 성능을 높이진 못했음 
- days는 모델 성능을 높여줌 -> 로그기록이 많을수록 문제제기 확률이 높다?
이경수
- 펌웨어, 모델 중 하나는 없에야할 듯
- day도 제외해봄 크게 상관없는 것 같음
- 퀄리티 데이터도 중요하고 연관성을 찾아야해서 중점적으로 살펴봄
- NaN이 많은 데이터가 있어 어떤 커ㅜㄹ리티는 제외해봐야할듯
- 아이디만 다르고 날짜,시간,펌웨어 같을 때 보니까 특정 부분만 숫자가 다름
-        시간이 다르면 특정 퀄리티가 올라가는 양상이 있나?
- 펌웨어를 바꿔봤는데 특정하지 못함
- 유저아이디 다르고 분단위로 봤을 때 비슷한 양상을 보였지만 확실하지 않음
- 확실한 거: 날짜가 달라지면 양상이 틀려짐
- 모든조건이 같아도 아이디에 따라 퀄리티가 다르다
정지영
- 군집화 해봄 - 유니크한 건 0번군집에 들어가기에 그대로 PCA함
- 11월 넘어가는 건 한 곳에 넣음
- 펌웨어 메이저 버전으로 바꾼뒤에 모델 숫자를 뒤어 붙여서 만듬
- 유저아이디마다 데이터 수가 적고 그런 사람도 고장이 많음
- 에러타입 발생할 확률 따로 만들어봄


**토론
거의다 모델이 같지만 모델이 다른 경우는 문제가 있어서가 아닌가 살펴봐야하지 않을까
problem은 사용자 불만 및 불만이 접수된 시간임으로 그전에 문제가 발생한거임
크리티컬 안했으면 접수를 안했다


정지영 - 에러타입 군집화, 에러코드 확률 
이경수 - 퀄리티 데이터 에러타입 관계 찾고, 머지해서 모델링 / 크리티컬한 문제가 있는지
양희정 - 크리티컬한 에러코드, 타입을 찾아보고 
윤준우 - 문제 제기한 시간을 어떻게 이용할지, 이를 이용해서 에러코드, 타입 narrow화


역할
데이터 전처리 1
EDA 1
피쳐 엔지니어링 2
모델링 (Tree-model, shap, bourta 등으로 feature selection 포함)

### 이때까지 한 것 

데이터 전처리
 - data type 변환
 - null 전처리

피처 preprocessing&generation
 - days feature 만들기
 - errorcode Label encoding
 - quality PCA using K-Means

모델링&스태킹
 - pycaret으로 자동 ensemble

### 진행 시 참고할만한 사항
Numeric Data - treebased model일때 feature scaling(minimax, std)에 영향을 받지 않음
Frequence Encoding - 지금처럼 user id fréquence encoding으로 진행시 최대 aux 0.85~6나올듯  - 뭔가 신선한 인사이트가 필요
quality 중 Null value가 많은 건 어떻게 다뤄야할지
quality 사용시 pca로 핸들링 했을 때 크게 작용하지 않음
특정 days와 errcode, errtype이 크게 작용함

### 데이터 고찰
- 오류는 분명 특이시점에 발생했는데 이를 무시하고 유저에게 오류가 발생했으면 전부 오류를 1로 치환한다? 그것은 조금 말이 안됌
- 사계열 데이터처럼 시간별 로그 기록이기 때문에 오류가 발생하기 이전에는 정상이였을 가능성이 있음
- 즉 오류가 발생한 시점 시간대만 1로 치환해보면 어떨까

## 2021년 1월10일
양희정
- 압축해서 상관관계살펴봄
- 특정 에러타입, 에러코드가 많거나 곂치는 게 있음
- 월,토,일이 생각보다 높음 (아마 많이 사용해서 그렇지 않을까 
-     모델4와 상관관계가 있었다
- nf안드로이드2 ->넷플릭스 오류라서 티비 관련이지 않을까
- lgb, xgb로 돌리는 중
- 파라미터최적화 손볼 예정

윤준우
- 문제 데이터 살펴봄
- 문제 데이터 시간대를 사용해 문제제기 전을 1, 제기 후(프로그램이 고쳐졌다는 가정하)0으로 라벨링함
- 1200만개:400만개 정도로 적당하게 분포되어있음
- 16000개 데이터만 문제제기 시간 대 로그가 있음
- 라벨링을 새로해서 모델링 다시 돌려보고 인사이트 추출할 예정

이경수
- 퀄리티 살펴봄
- 유저,펌웨어,데이같은 경우 그룹바이로 해서 퀄리티를 평균화 해봄
- 관계파악에 집중해보겠음

정지영
- 라벨,피쳐 상관관계 봤는데 별로 높게 안나옴
- 군집화, 모델펌웨어 합친것, 날짜도 낮게나옴
- 퀄리티 11이 좀 높게나옴

## 2021년1월11일
이경수
- 퀄리티 데이터 핸들링 (같은유저, 같은날짜, 같은 펌웨어)
- 퀄리티 평균내서 대입하고 모델링 중
양희정
- 메모장에 적어놓으신 퀄리티, 에러 분석 내용
정지영
- 에러코드 군집화가 아닌 트레인, 테스트 곂치는거 로 진행
- 퀄리티 11만 사용
- lab, 튜닝한 후 0.831
윤준우
- problem 제기한 시간 기준으로 이전을 0, 이후를 1로 라벨링 해서 돌려봄
- 0.02 좋아짐
이지수
  - xgb,lgb, cat boost 스태킹해봄
- 2차평가 준비

## 2021년 1월 12일

이경수
- 필요없는 err column 제거
- 퀄리티 평균 값 넣어 모델링
- 그리고 로그 전체로 돌려봤는데 AUC이 99.9로 높았음 (아마 인덱스 넣어서 오버피팅)
- 테스트 데이터 형식에 맞춰야 해서 고민중임
- 퀄리티 데이터 없는 유저들 나눠서 돌려봄

윤준우
- 문제발생 이전과 이후로 나눠서 라벨링한 모델을 테스트 데이터에도 적용해봄
- 압축이 아닌 로그 자체로 모델을 돌렸고, 유저마다 특정 로그가 문제 로그일 확률을 구한 것이기 때문에  같은 유저안에 0과 1데이터가 둘 다 있었다 (0이 1대10 비율로 적었다)
- 유저아이디 기준으로 gropby 해서 확률을 모두 다 더하여 평균냈고, 이를 제출하니 0.5가 나왔다 - 전처리 문제가 아닐까
- 풀어야 하는 문제 자체가 유저가 문제 제기한 시간을 맞추는 것이 아닌, 유저가 문제를 제기 했는지, 하지 않았는지에 대한 binary classification문제이다.
- 즉 시간을 활용하려면 이전, 이후로 나누어 라벨링 하는 게 아닌 다른 방식으로 해야하지 싶다.
- 퀄리티 데이터도 평균내어 전부 넣어 모델링 해보았지만 결과가 좋아지진 않았다.

양희정
- err전체 카운트를 넣어봤는데 아직 돌리는중임!
- 피쳐 몇개 뽑아서 돌려봤는데 좋아진 것은 없음
- 피쳐 Selection (퀄리티)

이지수
- 2차 평가 준비
- 에러타입 간에 상관관계 분석

정지영
- 퀄리티 데이터 11만 사용
- 평균값, 표준편차, 군집 보고 넣어봤는데 효과는 없었음
- 퀄리티 


Todo
- 이경수: 퀄리티 데이터 없는 유저들 나눠서 모델 돌려보기
- 윤준우: 퀄리티 데이터 없는 유저들 특징 (유저타입, 코드, 펌웨어 등) 살펴보기
- 양희정: 퀄리티 데이터를 포함한 Feature selection, extraction
- 정지영: 퀄리티 데이터 없는 유저들 특징 + 어떻게 전처리하여 붙일지 살펴보기
- 이지수: 에러타입, 코드 추가 분석하기

## 2021년 1월 13일

양희정
- 1650만개 훨씬 안좋게 나옴
- 테스트 중
윤준우
- 퀄리티데이터 있는유저 없는유저 나눠서 피쳐들 돌려보니 0.893, 0.832나옴
- 퀄리티데이터 있는 유저들 퀄리티 넣어 돌려봤는데 0.8이였음
- 퀄리티데이터 있는 유저들에 퀄리티 피쳐(min,max,mean,var,std)를 넣어 돌려봤는데 0.8이였음
- 퀄리티 데이터 있는 유저들에 높은 importance를 가진 퀄리티 피쳐만 넣어 돌려봤는데도 그대로임
- 퀄리티데이터 피쳐만 가지고 돌려봤는데 이건 더욱 안좋음 0.76
- 결국 퀄리티 데이터를 피쳐로 쓸 것이 아닌, 유저를 세분화 시켜 따로 모델링하는 방향으로 가야할 것 같음
이경수
- 퀄리티만 따로 분석해보니 max,min,mean 큰 결과가 없었다
- 퀄리티가 있지만 문제제기안한 인원이 있고 퀄리티가 없지만 문제제기한 인원이 있다
- 퀄리티와 에러타입 관계
정지영
- 퀄리티 데이터 최소,최대,분산 등을 사용해봤지만 별로 안좋아짐
- 피어슨, 피어만 상관관계를 이용해 퀄리티 데이터 전처리 해봄
- lab, catboost돌려봤는데 
- 모델별로 유저 나눠서 시도해보고 싶음


방향
- 퀄리티 데이터를 기준으로 유저를 나눈다
- 에러타입 기준으로 유저를 나눈다
- 에러코드 기준으로 유저를 나눈다
- 펌웨어를 기준으로 유저를 나눈다

- 15000개로 압축해서 진행한다
- 1600만개 데이터를 전부 사용한다

## 2021년 1월 13일 - 퀄리티 데이터 분석 요약
퀼리티 데이터 분석

user_id
퀄리티를 가지고 있는 유저 수: 	유저 15000명 중 8281명 (1600만개 중 580만개 로그) 
퀄리티를 가지고 있는 유저 분포: 	고름
각 유저의 퀄리티 로그 수  분포
	로그 수 4224~100: 1428명 (17%)   100~12 6853명 (83%)
	로그 수 4224~100: 문제제기 53%    100~12 문제제기  39%
	mean      100.063277	std       269.316318
	min         12			50%     24
	75%        72			max      4224

fwver
펌웨어 수: 전체 37개 중 28개 	하지만 전부 triain_error에 분포가 높은 펌웨어이다
펌웨어 분포:  상위 7개 펌웨어가 93.7%의 퀄리티 데이터를 차지한다 - train_err에서도 동일
	05.15.2138    163236		04.22.1750    142032
	04.33.1261    131340		04.16.3553     111996
	03.11.1167     104148		04.33.1185      66024
	04.22.1778     56472		04.22.1684       3420

time / day
요일 수:  		같음
요일 수 분포:	0(216) 빼고 골고루 분포되어있다.	train_err도 마찬가지(0,31,32 해당)
시간 수: 		같음
시간 수 분포:	골고루 되어있음 - 비교적 아침 시간대 3~11시가 로그수(사용량)이 적다

Quality 0 		-1 ~ 157667	754	결측값 (144432개)
Quality 1 		-1 ~ 171		31	
Quality 2 		799 ~ 191859	결측값 (40113개)
Quality 3 		전부 0
Quality 4 		전부 0
Quality 5 
Quality 6
Quality 7 
Quality 8 
Quality 9 
Quality 10 
Quality 11

1. 퀼리티 7/8/9/10/12 번은 같은 시간대에 무조건 한개의 값을 가진다. (여러행이라면 같은 값)
2. 퀼리티 0~12번 데이터 값중 -1이 있다면, 퀼리티 0/1/2/5/6/11 은 전부 무조건 -1값이다.
3. 퀼리티 3/4번 데이터 값은 전부 0이다.
4. 퀼리티 데이터 값 중 -1 값은 0/1/2/5/6/11번 퀼리티에만 있다.
5. 결측값은 퀼리티 0(144432개) / 2  / 5(20개) 에만 있다.
6. 퀼리티 0번과 2번의 상관관계를 매우 높을것으로 예상되며, 서로 같을 값일 확률이 매우 크다.
7. fwver 8.5.3 / 10 일 경우, 퀼리티 0과 퀼리티 2의 데이터는 수집되지 않는다.
8. fwver 03.11.1167 / 03.11.1149 일 경우 퀼리티 0번 데이터만 수집되지 않는다. (퀼리티 2번 데이터는 수집됨)
9. 퀼리티 5번 데이터값이 결측값일때, 퀼리티 10번의 데이터 값이 매우 크다.
10. 퀼리티 11번의 데이터 값이 1이라면, 퀼리티 12번의 데이터값은 무조건 1 이상이다.
11. 퀼리티 11번의 데이터 값이 1 이상이라면, 퀼리티 5/10번 데이터 값이 매우 큰 경향이 있다.
12. 퀼리티 10번의 데이터 값이 크다면, 퀼리티 5번의 데이터값이 큰 경향이 있다. (5번과 10번의 상관관계가 커보인다.)

에러데이터 분석
1. fwver == 10 일때, 에러코드는 전부 문자열값이다. 		B-A8002 /S-61001 /C-11017 /U-81000  /V-21003 /V-21007/ V-21008
2. fwver == 8.5.3 일때에도 에러코드는 전부 문자열 값이다. 	B-A8002 /S-61001 /M-99999  /V-21008
   또한 fwver 10/ 8.5.3 버젼은 모델6에만 있다. (모델 6번이 최신형 기기일 가능성이 높음)
2-1. 다만, 낮은 버젼의 fwver 에서도 문자열 에러코드값은 존재한다.
3. fwver 05. 이상 버젼은 모델 3, 7번에만 존재한다.
4. errtype 5 의 경우 errcode 는 거의 대부분 문자열 에러값.
5. errcode -269 데이터 2건은 아웃라이어 데이터같음.

## 2021년 1월 14일
이경수
  - 퀄리티 측정한 유저만 둘려봤을 때 0.8
- 퀄리티 측정 안한 유저만 돌려봤을 때도 0.8

정지영
 - 모델별로 분류하여 돌려봄
- 0,1,2는 0.83정도로 괜찮았는데 0.7후반대였음

윤준우
- EDA 전체적으로 정리해봄
- 퀄리티 있는 유저 없는 유저 0.825나와서 튜닝중
- 전체 로그로 돌려봐도 0.8이라 압축하나 안하나 비슷함

일단 각자 하는 분야를 더 살펴보고 좋은 결과가 나오지 않을 시 

좋게 나온 모델들만 가지고 모델링을 하던지 앙상블을 하던지 하고

각자 역할분담하여 진행하면 될듯함


submission = model1*0.3 + model2*0.4 + model3*0.2 + model4*0.1
AUC 잘나오는 순서대로 가중치를 두던지, 아니면 val set을 만들어서 가중치 자동화


데이터 leakage 찾기
- 케글하고는 달리 dacon은 첨부된 test data 중 일부를 나눠 private, public으로 나눠 점수를 메기기 때문에 테스트 데이터는 꼭 추론에서 사용하라 한다
- 즉 테스트 데이터에서 트레인 데이터에 중복된 값이나 패턴을 찾아낸 뒤 이를 활용하면 될 것이다 (물론 코드에는 안 보이게 할 것)
Time series 데이터 활용
- 사실 time series 데이터지만 이를 활용하고 있지 않음
- 시간별로 묶거나, 같은 시간 내 변화량, 같은 량 등을 피쳐 엔지니어링으로 만들어보자
- 문제가 발생한 시점을 기준으로 시간 차, 변화량 등을 사용해도 좋을 것이다
- 문제를 제기한 시간을 줬다는 이야기는 이를 기준으로 나누던가 활용하라는 이야기가 아닐까
피쳐 엔지니어링 작업
- 최대한 피쳐를 많이 뽑아내야한다
- 피쳐를 우리가 고르는게 아니고 최대한 여러 피쳐와 여러 모델을 통해 메타 모델링을 할 예정이기 때문
- 단 정말 쓸모없는 피쳐나 중복된 피쳐는 고려해보자 (quality3,4 예)

메타 모델링 기법 사용 
모델 1단계
lightgbm, catboost, gbc, rf, et등 최대한 많은 모델 수행 
- 각각 여러 변수들을 넣고 빼고 하여 만든다
- 예시) errtype, errcode 만 넣은 lightgbm
- 예시) model, days, errtype만 넣은  cat boost
- 얘시) model0,1,2,3,4 로 나눈 lightgbm

모델 2단계
prediction이나 auc이 잘나오는 모델을 선정해 5-fold bagging/stacking XGB를 실행해 최종 모델을 만든다

## 2021년 1월 15일
이경수
- 퀄리티있는 유저 없는 유저 나눠서 돌려보는중

윤준우
- 데이터 leakage, 중복값 찾음 -코드참조

정지영
- 모델, 펌웨어 나눠서 해봤는데 0.76
- 0.83에 hour feature, tuning 해봤는데 더 안좋아짐
- 상관관계 극대화 시켜보면 어떨 것 같은지 - error importance feature 넣어봤는데 그리 좋아지지 않음

이지수
- 품질 변화에 따라 어떻게 문제제기를 하는가
- 시간별 데이터를 고려해봐야하지 않을까 - 시간별 변화량에 따라 문제제기를 했냐 하지 않았느냐를 물어보는 것 같다

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
데이터 leakage 찾기
- 케글하고는 달리 dacon은 첨부된 test data 중 일부를 나눠 private, public으로 나눠 점수를 메기기 때문에 테스트 데이터는 꼭 추론에서 사용하라 한다 (케글은 오류없는 코드를 제출하고 그 코드에 숨겨둔 test 데이터를 돌려 public 점수를 매김)
- 즉 테스트 데이터에서 트레인 데이터에 중복된 값이나 패턴을 찾아낸 뒤 이를 활용하면 될 것이다 (물론 코드에는 안 보이게 할 것)
Time series 데이터 활용
- 사실 time series 데이터지만 이를 활용하고 있지 않음
- 시간별로 묶거나, 같은 시간 내 변화량, 같은 량 등을 피쳐 엔지니어링으로 만들어보자
- 문제가 발생한 시점을 기준으로 시간 차, 변화량 등을 사용해도 좋을 것이다
- 위 두가지 방법을 다른 대회 상위권 유저들이 많이 사용함
- 문제를 제기한 시간을 줬다는 이야기는 이를 기준으로 나누던가 활용하라는 이야기가 아닐까
피쳐 엔지니어링 작업
- 최대한 피쳐를 많이 뽑아내야한다
- 피쳐를 우리가 고르는게 아니고 최대한 여러 피쳐와 여러 모델을 통해 좋은 auc 모델 메타 모델링을 할 예정이기 때문
- 단 정말 쓸모없는 피쳐나 중복된 피쳐는 고려해보자 (quality3,4 예)

메타 모델링 기법 사용 
모델 1단계
lightgbm, catboost, gbc, rf, et등 최대한 많은 모델 수행 
- 각각 여러 변수들을 넣고 빼고 하여 만든다
- 예시) errtype, errcode 만 넣은 lightgbm
- 예시) model, days, errtype만 넣은  cat boost
- 얘시) model0,1,2,3,4 로 나눈 lightgbm

모델 2단계
prediction이나 auc이 잘나오는 모델을 선정해 5-fold bagging/stacking XGB를 실행해 최종 모델을 만든다

윤준우
Kaggle - 생산 라인 전 과정에서 시간별로 수집된 복잡한 데이터를 기반으로 불량품 탐지
전부 이 코드를 사용하여 아주 효과적이였다는데 finding data leakage (https://www.kaggle.com/mmueller/road-2-0-4)
잘 이해가 안됌 - 시작시간과 id를 기준으로 순서대로 나열한 다음, 다음 열이 같으면 1 아니면 0으로 나눈다는 이야기인 것 같은데…

1등
    - 2주를 eda하는데 보냄 - feature끼리 카운팅, 확률,  상관관계 등 어떻게 설명해주지 않은 feature들을 이용할지 고민함 - 우리기준 quality
    - 특정 feature별로 ordering 해서 feature을 뽑아냄 - 로그 숫자 등
    - 시간 feature을 많이 만들어냄
        - 다음 2.5, 24, 168시간마다 로그 갯수
        - 같은 분 내의 로그 갯수
        - 최근 문제 제기와 시간 차이
        - 다음 문제 제기와 시간 차이
    - 범주형 데이터를 처리 할 때 너무 많으면 크게 영향을 끼치지 않는 몇개는 군집화 함
    - 4 FOLD "leak-stratified" CV (forcing to have the same number of duplication for each fold) 를 사용했다는데 어떤게 same number of duplication인지 이해가 안감
    - 0라벨링은 다운샘플링함 

3등
    - 동일한 수치형 데이터를 가진 특정 데이터 값들이 높은 비율의 불량으로 이어지는 것을 사용함
    - 각 모델/펌웨어에서 동일한 날짜, 시간대에 실행되는 값을을 모아 새로운 변수를 추출함
    - 저희는 모든 모델/펌웨어별 시작일부터 종료일 기준으로 산출한 문제제기의 이동 평균을 기반으로 모델을 학슥함
    - 트리 기반 모델이 쉽게 추출하지 못하는 데이터의 래그(lag) 값 등을 추가함
    - 일반적인 피쳐 엔지니어링도 이용
        - 범주형 변수를 Bayesian 평균 값으로 인코딩 
        - 범주형 변수, 날짜 변수 및 수치형 변수의 고유 값 개수 
        - 모델과 펌웨어가 어떻게 변경된지 인코딩한 값 
        - 행별 수치형 변수 내 NA 개수, 모델/펌웨어 별 최대/최소 값
    - 1차 모델로 lightgbm, et, nn, rf, linear 등 160개 모델 사용
    - 모델 선정 후 좋은 모델들만 xgboost bagging
    - 1차 모델 과반수 투표 기법 + 2차 모델로 제출

4등
    - 비슷한 열이 얼마나 있는지 더해서 넣음
    - 섞어서 메타 모델링 -> 메타 피쳐와 문제가 있는 데이터만 모델링 -> xgboot, rf, et, kr해서 평균해서 넣음
    - 		
7등
    - 중복된 열만 골라서 훈련함 - N, N+1열이 비슷했다
    - 문제가 N열에 있을 시 N열과 붙어있으면서 비슷한 열만 1로 라벨링 나머지는 다 0으로 하였다
    - 다른 feature들
        - 특정 시간대로 나눈 그룹에 얼마나 많은 열이 있는지
            - 열이 엄청 많거나 엄청 적으면 문제가 있고 (1) 딱 중간 정도가 있었으면 (0)일 확률이 높았다
        - 특정 시간대는 다른 시간대 보다 문제가 생길 확률이 높았다 -> proximity by time (시간이 근접한지) 이 중요한 feature이였다
        - 시간대에 따라 얼마나 열 값이 유지되는지
        - 특정 행은 특히 중요하여 원핫 인코딩을 하였다
        - 문제있는 N열 다음. 또는 이전(N+1, N-1)열 들의 특정 행이 중요하게 작용하였다 
        - 지금 중복되는 부분이 어딘지 적었다 (총 유저 아이디에서 4개 그룹으로 나눠 중복된다 하였을 때 지금 열은 3번째 그룹)
        - 조금이라고 더 올리기 위해 한달동안 만든 모델들을 다 합쳐 메타 모델링을 사용했다 (xgb max_delta_step=1.5)
            - 만든 모델들의 확률들을 사용해 그게 1/0을 예측하는지 사용
7등에서 나온 인사이트
    - 라벨링을 문제가 생긴 범위 주위만 해보자
    - 전체 데이터 셋이 아닌 범위별로 나눠서 해보자 - 테스트 데이터도 같게 나누면 상관 없다
    - 비슷한 수치형/시계열 값을 가질 경우 동일한 문제 발생하는 그룹에 포함되어 문제 발생 확률이 유사할 것 (leakage 사용법)
    - 시작시간과 id를 기준으로 순서대로 나열한 다음, 다음 열이 같으면 1 아니면 0? 

8등
    - 1차 - lgbm, xgboost, rf, nn을 5개 데이터 셋으로 나누어 실행했음
        - 데이터 세트 1 (0.477 lgbm) - 순서, 숫자형 데이터, 날짜, 범주형 자료
        - 데이터 세트 2 (0.482 gbm, 0.477 xgb, 0.473 rf): 순서, fwver, 숫자형 데이터, 날짜
        - 데이터 세트 3(0.479 gbm, 0.473 xgb) : 순서, fwver, 숫자형 데이터, 날짜, 정제한 범주형 자료
        - 데이터 세트 4(0.469 xgb, 0.442 rf) : 숫자형 데이터 / 날짜 /  최근접이웃탐색(L1 맨해탄, L2 유클리디안 거리) 별로 sorting
        - 데이터 세트 5(0.43 xgb) : fwver,  최근접이웃탐색
    - 2차 - 위 모델에서 나온 예측값과, 데이터셋5, 몇몇 feature 사용
    - 30% 2차 xgb(0.488)과 70% rf(0.485) 스태킹함
    - feature engineering 예시들
        - 시간별로 차이, kurtosis
        - lead lag feature generation  -> 특정 그룹id와 날짜/시간 기준으로 정렬(sorting)을 해놓은 다음에, lead() 나 lag() 함수를 가지고 행을 하나씩 내리구요, 직전 날짜/시간 대비 이후의 값의 변화, 차이(difference)를 구한다
    - 마지막 합칠 때 여러 제출 파일들을 4fold로 variance 측정한 뒤 OOF로 AUC, threshold, positive rate, true positive, false negative 측정해서 결과가 최대한 비슷한지 살펴봄
￼
￼





